{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yamamotomasaomi/.pyenv/versions/anaconda3-5.1.0/envs/makuwo/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/yamamotomasaomi/.pyenv/versions/anaconda3-5.1.0/envs/makuwo/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "fp = FontProperties(fname=r'/system/library/fonts/ヒラギノ角ゴシック W0.ttc', size = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-97dbbb1effaf>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/yamamotomasaomi/.pyenv/versions/anaconda3-5.1.0/envs/makuwo/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/yamamotomasaomi/.pyenv/versions/anaconda3-5.1.0/envs/makuwo/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/yamamotomasaomi/.pyenv/versions/anaconda3-5.1.0/envs/makuwo/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/yamamotomasaomi/.pyenv/versions/anaconda3-5.1.0/envs/makuwo/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, labels = mnist.train.next_batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "%matplotlib inline\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize=(8,4))\n",
    "for c, (image,label) in enumerate(zip(images,labels)):\n",
    "    subplot = fig.add_subplot(2,5,c+1)\n",
    "    subplot.set_xticks([])\n",
    "    subplot.set_yticks([])\n",
    "    subplot.set_title('%d' % label)\n",
    "    subplot.imshow(image.reshape((28,28)), vmin = 0, vmax=1, cmap=plt.cm.gray_r, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import multivariate_normal,permutation\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "np.random.seed(20160512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,[None, 784])\n",
    "w = tf.Variable(tf.zeros([784, 1]))\n",
    "w0 = tf.Variable(tf.zeros([1]))\n",
    "f = tf.matmul(x, w) + w0\n",
    "# p = tf.nn.softmax(f)\n",
    "p = tf.sigmoid(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.placeholder(tf.float32, [None, 1])\n",
    "# loss = -tf.reduce_sum(t * tf.log(p))\n",
    "loss = -tf.reduce_sum(t*tf.log(p) + (1-t)*tf.log(1-p))\n",
    "train_step = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_prediction = tf.equal(tf.sign(p-0.5),tf.sign(t-0.5))\n",
    "correct_prediction = tf.equal(tf.argmax(p, 1), tf.argmax(t, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "batch_xs, batch_ts = mnist.train.next_batch(100)\n",
    "batch_ts = (batch_ts ==2)\n",
    "batch_ts = batch_ts.reshape(100,1).astype(int)\n",
    "p_val = sess.run(p, feed_dict={x:batch_xs, t:batch_ts})\n",
    "\n",
    "for _ in range(1000):\n",
    "    i += 1\n",
    "    for (image, label, pred) in zip(batch_xs, batch_ts, p_val):\n",
    "        prediction, actual = np.argmax(pred), label\n",
    "        sess.run(train_step, feed_dict={x:batch_xs,t:batch_ts})\n",
    "#     if  batch_ts[i]==2:\n",
    "#         print (prediction)\n",
    "#         print (batch_ts[i])\n",
    "    if i % 100 == 0:\n",
    "        loss_val, acc_val = sess.run([loss,accuracy],feed_dict={x:batch_xs,t:batch_ts})\n",
    "        print ('Step:%d, Loss:%f, Accuracy:%f' % (i, loss_val, acc_val) )\n",
    "        print (prediction)\n",
    "        print (batch_ts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "train_y = []\n",
    "test_y = []\n",
    "for _ in range (2500): \n",
    "    sess.run(train_step,feed_dict={x:batch_xs,t:batch_ts})\n",
    "    loss_val =sess.run(loss, feed_dict={x:batch_xs,t:batch_ts})\n",
    "    train_y.append(loss_val)\n",
    "#     loss_val =sess.run(loss, feed_dict={x:test_x,t:test_t})\n",
    "#     test_y.append(loss_val)\n",
    "    \n",
    "    acc_val =sess.run(accuracy, feed_dict={x:batch_xs,t:batch_ts})\n",
    "    train_accuracy.append(acc_val)\n",
    "#     acc_val =sess.run(accuracy, feed_dict={x:test_x,t:test_t})\n",
    "#     test_accuracy.append(acc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 復習\n",
    "先週のは、Mnistを使った分類法について一応分類して見ましょうと言う話ではあるが\n",
    "とにかく、Mnistを触ってみようと言う意味合いでやって見た次第というわけ\n",
    "これから先、別のも動かしてみようということになった\n",
    "mnistをもちいて、これまでのロジスティック回帰をしてもらおうということになったのだ\n",
    "\n",
    "例えば、０かそうでないかという分岐をしてみよう\n",
    "０か否か（正答率に関する話ということなので、選択肢が２択であれば、問題はない。今までのデータをもちいて、できるはずなので、やってみよう。）\n",
    "\n",
    "Mnistの中では、全部で7万もの筆跡のデータが入っているんです。\n",
    "訓練用（学習用）:train 55000個\n",
    "テスト用:test 10000個\n",
    "バリエーション:variation 5000個\n",
    "無論すべてを使う事はできるが、わけて使うほうが普通のやり方（過学習の予防）\n",
    "\n",
    "# 取り出し方\n",
    "mds-02にて、mnistが取り出されている\n",
    "mnist.train(クラスと同じ扱い)\n",
    "\n",
    "以下のようなオプションが存在する\n",
    "image => 画像\n",
    "label =>　画像の何が書かれているかのデータ\n",
    "\n",
    "tarain = mnist.train.images => 配列の中みすべてを表す\n",
    "55000通りのベクトルを示している。\n",
    "\n",
    "one_hot => ラベルをどういう具合に表現するのか？=>ひとつひとつが１０個のベクトルとして表される\n",
    " True: [0,0,1,0,0,0,0,0,0,0]\n",
    "false:3\n",
    "\n",
    "テキストはTrueとなっている。\n",
    "今はFalseにすれば、問題の条件式を作れるはず。\n",
    "\n",
    "<b>この中で数字が0かどうかでラベルをつけ直す</b>\n",
    "train0_labels=>(train.labels == 0)\n",
    "true,falseを返すようにする。\n",
    "\n",
    "何個はいってる？＝＞trueを何個あるかを出せば良い\n",
    "\n",
    "np.sum(train0_labels) => 1の個数が出る\n",
    "\n",
    "mle-05(p.73)\n",
    "x=tf.placeholder [None.2] =>感染非感染で２にしてた。しかし、ベクトルなので784次元となるはずだ。つまり、それらの数値も次元を理解してないと意味がない。\n",
    "シグモイド関数を使用して、\n",
    "t = tf.placeholder([None,1])でよい。\n",
    "optimizerもそのまま。学習すれば良い。\n",
    "\n",
    "学習回数は、2万回でやってるが、今回は、1000回くらいで平気。\n",
    "\n",
    "# 評価\n",
    "今、trainで話をしたが、testも用意する事。学習した評価をtestで行う事。\n",
    "こちらも、以前と同じプログラムを流用する形。\n",
    "テストする数は10000。\n",
    "2という文字について、テストの1万個の中に、本当に2というものと、本当に2でないというものがある。\n",
    "予想が2である事と2でない判定がある。\n",
    "それぞれを表で表すため、４通りになる。\n",
    "\n",
    "```\n",
    "本当に０でない　＝　０でない　＝＞真陽性（TN）\n",
    "０である　＝　０である　＝＞真陽性（TN）\n",
    "本当に０でない　＝　０である　＝＞　偽陽性（PP）\n",
    "０である　＝＞　０でない　＝＞　偽陰性（PN）\n",
    "```\n",
    "## 混同行列\n",
    "recall = TP/FN＋TP 再現率\n",
    "prediction_2 = TP/Tp+FP\n",
    "\n",
    "prediction = (p>=0.5)\n",
    "tensor flowで定義したものなので、使える。学習した後、求めてやると、判定結果が出るように設定する。\n",
    "sess.run(prediction, feed_dict ={x:train.image t:test.label})\n",
    "\n",
    "Andでつなげてあげれば、IF文は完成する。\n",
    "\n",
    "reshapeするのは２次元のベクトルに変換するため。縦ベクトル（何行✖️1にするため。Tの定義と合わないので）\n",
    "つまり、test.labelは、reshapeされる必要がある。[-1,1]にしておく事で勝手に計算してくれる。\n",
    "\n",
    "判定結果のTrue,Falseが返されるので、\n",
    "\n",
    "PCパームレストと、猫の旅雑誌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.title('ロジスティック回帰による二項分類器',fontproperties=fp)\n",
    "subplot = fig.add_subplot(1,2,1)\n",
    "subplot.plot(range (len(train_accuracy)),train_accuracy,linewidth=2,label='Training set')\n",
    "# subplot.plot(range (len(test_accuracy)),test_accuracy,linewidth=2,label='Test set')\n",
    "plt.legend([u'トレーニングケース', 'テストケース'], prop=fp, loc='lower right')\n",
    "fig.xlabel=(u'epoch')\n",
    "fig.ylabel=(u'accutacy')\n",
    "\n",
    "\n",
    "subplot2 = fig.add_subplot(1,2,2)\n",
    "subplot2.plot(range(len(train_y)),train_y,linewidth=2,label='トレーニングセット')\n",
    "# subplot2.plot(range(len(test_y)),test_y,linewidth=2,label='テストセット')\n",
    "plt.legend([u'トレーニングケース', 'テストケース'], prop=fp, loc='upper right')\n",
    "plt.xlabel=(u'epoch')\n",
    "plt.ylabel=(u'loss/sample')\n",
    "# subplot.legend(loc='upper left')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('file.csv', 'wt') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(batch_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0_val, w_val= sess.run([w0,w])\n",
    "w0_val, w1_val, w2_val = w0_val[0], w_val[0][0], w_val[1][0]\n",
    "print (w0_val, w1_val, w2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_ts[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_makuwo)",
   "language": "python",
   "name": "conda_makuwo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
